{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Notebook is designed to implement various Big Data algorithms using Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, LinearSVC,NaiveBayes, GBTClassifier\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results = {}\n",
    "\n",
    "def transform_data(data, input_cols, output_col):\n",
    "    assembler = VectorAssembler(inputCols=input_cols, outputCol=\"features\")\n",
    "    data = assembler.transform(data)\n",
    "    data = data.select(['features', output_col])\n",
    "    return data\n",
    "\n",
    "def evaluate_model(model, data, model_name , date_type):\n",
    "\n",
    "    # prdict on data\n",
    "    predictions = model.transform(data)\n",
    "\n",
    "    # Create evaluators for different metrics\n",
    "    evaluator_multi = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='loanStatus', metricName='accuracy')\n",
    "    evaluator_weighted_precision = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='loanStatus', metricName='weightedPrecision')\n",
    "    evaluator_weighted_recall = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='loanStatus', metricName='weightedRecall')\n",
    "    evaluator_f1 = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='loanStatus', metricName='f1')\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = evaluator_multi.evaluate(predictions)\n",
    "    weighted_precision = evaluator_weighted_precision.evaluate(predictions)\n",
    "    weighted_recall = evaluator_weighted_recall.evaluate(predictions)\n",
    "    f1 = evaluator_f1.evaluate(predictions)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Model: {model_name} - {date_type}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Weighted Precision: {weighted_precision}\")\n",
    "    print(f\"Weighted Recall: {weighted_recall}\")\n",
    "    print(f\"F1: {f1}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    Results[model_name + \" - \" + date_type] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Weighted Precision\": weighted_precision,\n",
    "        \"Weighted Recall\": weighted_recall,\n",
    "        \"F1\": f1\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(train_data, test_data, output_col):\n",
    "\n",
    "    # Create Logistic Regression model\n",
    "    lr = LogisticRegression(featuresCol='features', labelCol=output_col)\n",
    "\n",
    "    # Fit model to training data\n",
    "    lr_model = lr.fit(train_data)\n",
    "\n",
    "    evaluate_model(lr_model,train_data, 'Logistic Regression', 'train')\n",
    "    evaluate_model(lr_model,test_data, 'Logistic Regression', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(train_data, test_data, output_col):\n",
    "\n",
    "    # Create Decision Tree model\n",
    "    dt = DecisionTreeClassifier(featuresCol='features', labelCol=output_col)\n",
    "\n",
    "    # Fit model to training data\n",
    "    dt_model = dt.fit(train_data)\n",
    "\n",
    "    evaluate_model(dt_model,train_data, 'Decision Tree', 'train')\n",
    "    evaluate_model(dt_model,test_data, 'Decision Tree', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(train_data, test_data, output_col):\n",
    "\n",
    "    # Create Random Forest model\n",
    "    rf = RandomForestClassifier(featuresCol='features', labelCol=output_col)\n",
    "\n",
    "    # Fit model to training data\n",
    "    rf_model = rf.fit(train_data)\n",
    "\n",
    "    evaluate_model(rf_model,train_data, 'Random Forest', 'train')\n",
    "    evaluate_model(rf_model,test_data, 'Random Forest', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_svc(train_data, test_data, output_col):\n",
    "\n",
    "    # Create Linear SVC model\n",
    "    lsvc = LinearSVC(featuresCol='features', labelCol=output_col)\n",
    "\n",
    "    # Fit model to training data\n",
    "    lsvc_model = lsvc.fit(train_data)\n",
    "\n",
    "    evaluate_model(lsvc_model,train_data, 'Linear SVC', 'train')\n",
    "    evaluate_model(lsvc_model,test_data, 'Linear SVC', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosted_tree(train_data, test_data, output_col):\n",
    "\n",
    "    # Create Gradient Boosted Tree model\n",
    "    gbt = GBTClassifier(featuresCol='features', labelCol=output_col)\n",
    "\n",
    "    # Fit model to training data\n",
    "    gbt_model = gbt.fit(train_data)\n",
    "\n",
    "    evaluate_model(gbt_model,train_data, 'Gradient Boosted Tree', 'train')\n",
    "    evaluate_model(gbt_model,test_data, 'Gradient Boosted Tree', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(data, input_cols, output_col):\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    train_data, test_data = data.randomSplit([0.8, 0.2])\n",
    "\n",
    "    # Transform data\n",
    "    train_data = transform_data(train_data, input_cols, output_col)\n",
    "    test_data = transform_data(test_data, input_cols, output_col)\n",
    "    \n",
    "    # Logistic Regression\n",
    "    logistic_regression(train_data, test_data, output_col)\n",
    "\n",
    "    # Decision Tree\n",
    "    decision_tree(train_data, test_data, output_col)\n",
    "\n",
    "    # Random Forest\n",
    "    random_forest(train_data, test_data, output_col)\n",
    "\n",
    "    # Linear SVC\n",
    "    linear_svc(train_data, test_data, output_col)\n",
    "    \n",
    "\n",
    "    # Gradient Boosted Tree\n",
    "    gradient_boosted_tree(train_data, test_data, output_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression - train\n",
      "Accuracy: 0.8146817937701396\n",
      "Weighted Precision: 0.8105080638642768\n",
      "Weighted Recall: 0.8146817937701396\n",
      "F1: 0.8088251485176786\n",
      "\n",
      "\n",
      "Model: Logistic Regression - test\n",
      "Accuracy: 0.8167432192308982\n",
      "Weighted Precision: 0.8127412825281367\n",
      "Weighted Recall: 0.8167432192308982\n",
      "F1: 0.8107583491773064\n",
      "\n",
      "\n",
      "Model: Decision Tree - train\n",
      "Accuracy: 0.8324214554242749\n",
      "Weighted Precision: 0.8357703380858977\n",
      "Weighted Recall: 0.8324214554242749\n",
      "F1: 0.8222478812566576\n",
      "\n",
      "\n",
      "Model: Decision Tree - test\n",
      "Accuracy: 0.830757367485835\n",
      "Weighted Precision: 0.8338681879178533\n",
      "Weighted Recall: 0.8307573674858351\n",
      "F1: 0.8203905134762592\n",
      "\n",
      "\n",
      "Model: Random Forest - train\n",
      "Accuracy: 0.8152775912996778\n",
      "Weighted Precision: 0.8242739838302515\n",
      "Weighted Recall: 0.8152775912996777\n",
      "F1: 0.7992995112696921\n",
      "\n",
      "\n",
      "Model: Random Forest - test\n",
      "Accuracy: 0.817011432594629\n",
      "Weighted Precision: 0.8260243932889866\n",
      "Weighted Recall: 0.817011432594629\n",
      "F1: 0.8012994344782566\n",
      "\n",
      "\n",
      "Model: Linear SVC - train\n",
      "Accuracy: 0.8133265641783028\n",
      "Weighted Precision: 0.8093891380282847\n",
      "Weighted Recall: 0.813326564178303\n",
      "F1: 0.8063994734822167\n",
      "\n",
      "\n",
      "Model: Linear SVC - test\n",
      "Accuracy: 0.8157038924464411\n",
      "Weighted Precision: 0.8120142308532361\n",
      "Weighted Recall: 0.8157038924464413\n",
      "F1: 0.8087074152135005\n",
      "\n",
      "\n",
      "Model: Gradient Boosted Tree - train\n",
      "Accuracy: 0.8920767320085929\n",
      "Weighted Precision: 0.895298891164756\n",
      "Weighted Recall: 0.8920767320085929\n",
      "F1: 0.8881649091183957\n",
      "\n",
      "\n",
      "Model: Gradient Boosted Tree - test\n",
      "Accuracy: 0.8916920910584369\n",
      "Weighted Precision: 0.8948200574149167\n",
      "Weighted Recall: 0.891692091058437\n",
      "F1: 0.8877662380593386\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('classification').getOrCreate()\n",
    "\n",
    "# Load data\n",
    "train_data = spark.read.csv('dataset/preprocessed_train.csv', header=True, inferSchema=True)\n",
    "test_data = spark.read.csv('dataset/preprocessed_test.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Define input columns and output column\n",
    "input_cols = train_data.columns[1:-1]\n",
    "output_col = 'loanStatus'\n",
    "\n",
    "transformed_train_data = transform_data(train_data, input_cols, output_col)\n",
    "transformed_test_data = transform_data(test_data, input_cols, output_col)\n",
    "\n",
    "pipeline(train_data, input_cols, output_col)\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "with open('results_new.txt', 'w') as f:\n",
    "    for key in Results.keys():\n",
    "        f.write(\"%s,%s\\n\"%(key, Results[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
